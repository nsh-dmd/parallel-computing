\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr} % Required for custom headers
%\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{ulem} % underline emph
\usepackage{amsmath} % for \text in mathmode
\usepackage[hypcap]{caption}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0.5in
\textwidth=5.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.3} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{} % Top left header
\chead{\hmwkClass: \hmwkTitle} % Top center head
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{\thepage} % Bottom center footer
%\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{C} % Load C syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf
\lstset{language=C, % Use python in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % C functions bold and blue
        keywordstyle=[2]\color{Purple}, % C function arguments purple
        keywordstyle=[3]\color{Blue}, % Custom functions \underbar underlined and blue
        identifierstyle=, % Nothing special about identifiers                                         
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Python functions not included in the default language here
        morekeywords={rand},
        %
        % Put Python function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{glutCreateWindow,p},
        %
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=none, % can use none % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=1 % Line numbers go in steps of 5
}
% \usepackage{graphicx}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\code}[1]{
\begin{itemize}
\item[]\lstinputlisting[label=#1]{#1.c}
%\item[]\lstinputlisting[caption=#2,label=#1]{#1.c}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%   DOCUMENT STRUCTURE COMMANDS
%   Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

\setcounter{secnumdepth}{0} % Removes default section numbers

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
    \renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
    \section{\homeworkProblemName} % Make a section in the document with the custom problem count
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
    \noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
    \renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
    \subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
}

%----------------------------------------------------------------------------------------
%   NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Problem set 4, Part 1\\ Theory} % Assignment title
\newcommand{\hmwkDueDate}{\date{Oktober 12, 2016}} % Due date
\newcommand{\hmwkClass}{TDT4200} % Course/class
\newcommand{\hmwkAuthorName}{Neshat\ Naderi}  % Your name


%----------------------------------------------------------------------------------------
%   TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\vspace{2in}
\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
\normalsize\vspace{0.1in}\normalsize{\hmwkDueDate}
\vspace{0.1in}\large{\text{Parallel Computing}}
\vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------
\begin{document}
\maketitle

\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

% \newpage
% \tableofcontents
%\newpage

%----------------------------------------------------------------------------------------
%   PROBLEM 1
%----------------------------------------------------------------------------------------

% To have just one problem per page, simp   ly put a \clearpage after each problem
\clearpage

\section{Part 1, Theory}
\subsection{Problem 1, Memory and Caching}
\begin{flushleft}
a) Three types of cache mises are \textit{compulsory misses}, \textit{capacity misses} and \textit{conflict misses}.
\begin{enumerate}
\item \textit{Compulsory} or \textit{cold misses} cause by the first reference to a cache line that is never requested before or not currently. These type of misses can be avoided by \textit{software} and \textit{hardware prefetching}. So before the program stalles, required data can be loaded into the cache before that cache line is needed. \\
In software prefetch the programmer or compiler sets instructions for loading data, and it doese not stall waiting for data to be loaded to the cache.\\
By hardware prefetching the processor moniters program's memory access so that it can predict what access the program will do. Then that data can be prefetched to cache. 
\item \textit{Capacity miss} occures when the executing program has a large working set and need more capacity than cache capacity is provided. Capacity miss could be avoided by for example higher cache associativity or larger memory block size. Blocking instruction in hardware prefetching improves temporal locality therefore it can reduce capacity misses.
\item \textit{Conflict} or {collision misses} are those in case of set assosiative or direct mapped replacement policies. When memory blocks are mapped to the same set or block frame conflict misses occure. Conflict detection tables and associativity to allow locations being mapped to multiple cache entries can be to help for reducing conflict misses. Due to associativity's added complexity the cache access slows down. So keeping associativity low is crucial.
\end{enumerate}
Generally, cache misses could be recuded by different methods. Such as, higher associativity, larger block size, software prefetching, hardware prefetching data and instructions, and compiler optimizations such as loop unrolling, loop merging and etc. Each of these methods have their own advantages and drawback. So taking complexity in mind the suitable method should be chosen.

\end{flushleft}
\begin{flushleft}
b) In all loops accessing \texttt{i} is exhibits temporal locality.
I) Spatial locality. References array elements \texttt{a[i]} that are neighbor elements each and these elements' location is close to eachother. 
\begin{lstlisting}
for(int i = 0; i < 10000; i++){
      a[i] = b[i] + c[i];
}
\end{lstlisting}

II) Temporal locality. Cycling through loop instructions is temporal and the operation in the inner loop is repeated $100$ times. So those $100$ elements are accesed again in the next iteration which is in very close time slot. So accessing memory locations in close time points to temporal locality. \\
(We could also say that referencing instructions sequentially that is accessing vector elements in the inner loop, exhibits spatial locality.)
\begin{lstlisting}
for(int i = 0; i < 100; i++){
    for(int j = 0; j < 100; j++){
          a[j] = b[j] + c[j];
      }
}
\end{lstlisting}
III) Temporal locality on accessing \texttt{a[j*1000]}, \texttt{b[j*200]} and \texttt{c[j*3000]}. Same elements are accessed in very close time(after 10 iterations).\\
This loop is similar to the previuos one, but here we don't have spatial locality because the vector elements are not placed close to eachother.
\begin{lstlisting}
for(int i = 0; i < 100; i++){
    for(j = 0; j < 10; j++){
        a[j*1000] += b[j * 2000] + c[j * 3000];
    }
}
\end{lstlisting}
\end{flushleft}


\begin{flushleft}

\end{flushleft}
\newpage

\subsection{Problem 2, Branching}
a) A \textit{branch predictor} gusses whether a conditional jump will be taken or not. Branch prediction helps improving performance of instruction pipeline. There are two kinds of branch predictions, \textit{static} and \textit{dynamic prediction}.\\
If processor's branch prediction is based on static prediction, it assumes that a branch will always be taken or always not taken and it's prediction is based on the branch instruction. Static prediction is displacement based, so branches forward in memory will fall through while branches backward in memory jump. This works best on TRUE \texttt{if} statements and loops repeating more than once.
In the other hand a dynamic predictor remembers recent taken or not taken conditional jump of a code execution. It uses a branch prediction buffer or branch history table.\\
For instance a 4-stage pipeline includes \textit{fetch, decode, execute} and \textit{write back} stages. Predicting the branch outcome avoids a processor of stalling until a conditional branch finished the execution stage before the next instruction can start a fetch stage. So by a correct prediction of the most likely direction, the wasted time when processor waited is avoided. So a pipelined microprocessor can achieve higher performance. In case of branch misprediction the mispredicted branch instruction is discarded and the correct branch is started with delay. the wasted time for executing the correct branch is equal to the number of pipeline stages from the fetch to execute stage. Because the pipeline startes over the correct branch.\\~\\



% \newpage
b) 
\begin{enumerate}[I)]
    \item $r < \frac{p-\frac{b}{n}}{f-s} $
    \item $ r < \frac{n-s-p}{2b+f-s} $
    \item $ (2b)r^2 + (2p-2b+f+s)r + p > 0 $ 
\end{enumerate}
Assumed\\
\# special elements $=k= nr$ \\
\# normal elements $=l= n(1-r)$\\
Running time for special elements is $f+p$ and for others is $s+p$. $p$ time is applied in both cases. In all alternatives $k$ and $l$ is multiplied by $(f+p)$ and $(s+p)$. \\
Running all elements with \texttt{slow()} function will cost $sn$. \\
So in each case the number of mispredictions are calculated and multiplied with $b$

So it would be beneficial removing the branch if \\~\\
\begin{enumerate}[I)]

    \item All elements are placed in the start. Therefor only one misprediction happens and $b$ is applied only once.
	\begin{align*}
	(f+p)nr + b + (s+p)n(1-r) < sn  \\
	(fn)r+(pn)r+b+(sn+pn)-(sn+pn)r < sn \\ 
	n(f-s)r + b + n(s+p) < sn \\
	\underline{\underline{r< \frac{p-\frac{b}{n}}{f-s}}}
	\end{align*}

    \item The number of mispredictions is $2k$ because of even distribution.
	\begin{align*}
	(2nr)b + nr(p+f) + n(1-r)(s+p) < sn \\
	r(2b+p+f) + s+p-r(s+p) < sn \\
	\underline{\underline{r<\frac{n-s-p}{2b+f-s}}}
	\end{align*}

    \item The total number of mispredictions is $2n(r-r^2)$. Probability for special elements is $r$ and for the ordinary ones is $1-r$. So we get the total probability as $r(1-r) + (1-r)r$. So the total mispredictions is $n[ r(1-r) + (1-r)r]$.
	\begin{align*}
	n[2(r-r^2)b + r(p+f) + (1-r)(s+p)] < sn \\
	2(r-r^2)b + r(p+f) + s+p - r(s+p) < s \\
	(2b)r^2 + (2p-2b+f+s)r +p > 0
	\end{align*}
	\end{enumerate}

\subsection{Problem 3, Vectorization}
\begin{flushleft}
a) ADD, CMP, MOV, INC are some of SIMD instructions. SIMD instruction on x86 processors is an instruction that applies same operation on multiple data elements at the same time and could increase the preformance greatly. 


\end{flushleft}
\begin{flushleft}
b) Assumes each element in array is a float of $32$ bits.\\
\begin{enumerate}[I)]

\item $128 b = 4\ *\  32\ bit $, so 4 times faster. 
\item $512 b = 16\ *\ 32\ bit $, so 16 times faster.

\end{enumerate}

\end{flushleft}
\newpage
\subsection{Problem 4, Optimization}
\begin{enumerate}
    \item Reprogram the recrusiv factorial function with a loop. See Listing 1.
    \item Use the same loop for calculating factorial and calculating $sin(x)$. See Listing 2.
    \item Remove conditional branch by doing extra work in each loop iteration. See Listing 3.
    \item Get rid of pow function. See Listing 4.
    
\end{enumerate}

\begin{lstlisting}[caption={Factorial function operates using a loop}]
double factorial(int n) {
	double fact = 1
	for (size_t i = 0; i < n; i++) {
		if(n < 2) {
			return 1;
		}
		fact *= i;
	}
	return fact;
}

double slow_sin(double x) {

	double r=0; int i;

	for (int i = 1; i < 100; i ++) {

		if(i%2==0) {
			r +=  pow(x, i*2+1) / (factorial*(i*2+1));
		}
		else {
			r -= pow(x, i*2+1) / (factorial*(i*2+1));
		}
	}
	return r;
}
\end{lstlisting}
\newpage
\begin{lstlisting}[caption={Calculate factorial in the slow\_sin loop.}]
double slow_sin(double x) {

	double r=0; int i;
	double factorial = 1;

	for (i = 0; i < 100; i ++) {

		if(n > 2) {
			factorial *= i+1;
		}

		if(i%2==0) {
			r +=  pow(x, i*2+1) / factorial;
		}
		else {
			r -= pow(x, i*2+1) / factorial;
		}
	}
	return r;
}
\end{lstlisting}
\begin{lstlisting}[caption=Getting rid of conditional branches from the \texttt{slow\_sin} loop instead.]
double slow_sin(double x) {
    
    int i;
	double r_odd=0; double r_even = x;
	double factorial = 1;

	for (i = 1; i < 100; i += 2) {

		factorial *= i;
		r_odd -= pow(x, i*2+1) / factorial;
		r_even += pow(x, (i+1)*2+1) / (factorial*(i+1));
	}
	return r;
}
\end{lstlisting}
\newpage

\begin{lstlisting}[caption=Optimized function $sin(x)$ using Talor series.]
double optimized_sin(double x) {
    
    inti;
    double r_odd=0; double r_even = x;
    double factorial = 1;
    double pow_x = x;

    for (i = 1; i < 100; i += 2) {

        factorial *= i;
        pow_x *= x * x;

        r_odd -= pow_x/ factorial;
        r_even += pow_x * x * x/ (factorial*(i+1));
    }
    return r_even + r_odd;
}
\end{lstlisting}
\subsection{Problem 5, OpenMP schedules}
Scheduling types are described below
\begin{itemize}
    \item Static, divides work in equal chuncks to assign to each thread. It is not suitable for iterations taking different amount of time. But here it take same time running compute in each iteration.
\begin{lstlisting}
#pragma omp for schedule(static) 
for(int i = 0; i < 1024; i++) {
	int arg = 100;
	compute(arg)'
}
\end{lstlisting}
    \item Dynamic. In this case the workload is imbalanced when \texttt{arg} is defined with \texttt{rand} function. So when a thread is finished with an iteration, it will stop and will be asssigned a new chunk of work.
\begin{lstlisting}
#pragma omp for schedule(dynamic) 
for(int i = 0; i < 1024; i++) {
	int arg = rand() % 100;
	compute(arg)'
}
\end{lstlisting}

    \item Guided. Chunk size changes as the program runs. The next chunck size for threads is decreased in each iteration. So when computing \texttt{pow(i,i)} the work load is increased in each iteration and because of this reason using guided scheduling policy will make the computation faster.
\begin{lstlisting}
#pragma omp for schedule(guided)
for(int i = 0; i < 1024; i++) {
	int arg = pow(i, i);
	compute(arg)'
}
\end{lstlisting}
Here the work in arg gets more and more time after each iteration.
\end{itemize}

\end{document}
